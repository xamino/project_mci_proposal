The most basic interaction aspect we have to consider is whether interaction is active – meaning initiated by the user – or passive – meaning that the system reacts to stimuli apart from direct user input.
This has profound consequences for how the system would work and what it can be used for.
For example some tasks only work well with direct interaction, no matter the capabilities of the system, such as text input.

Apart from active or passive interaction we have to consider whether the system will work via a WIMP interface or if it will use a more metaphorical physical interaction scheme.
WIMP is the standard for computing and widely in use; no mental work is required when switching to the system if that is used.
A physical representation however is more intuitive.
Nevertheless, no standards exist (meaning most systems that are based on that work differently) and the discrepancy between the representation and the real world will always be a limiting factor.

Another aspect that needs to be considered is how and if we differentiate between multiple users per device.
This aspect has to be considered for targeting output and for identifying input and is called proximal regions.
For example if only one person is in a room we can use the complete room for input and output without differentiation.
If multiple users are within a room we will possibly be required to differentiate to the best of our capabilities based on the input and output hardware capabilities.
These capabilities are hardware dependent and therefore listed in the upcoming sections.
Independent of that, this decision is mainly influenced by the task the system will fulfill (meaning is differentiation required or can it be ignored?).

\subsection{Input – Interaction Spaces}

From an interaction standpoint, we can classify the different input possibilities for their distance to the device that will receive the input.

The first category is input \textbf{directly on the device}, for example with the nowadays popular touch screen technology.
With a capable device, this input method allows fast and direct feedback that is immediately apparent to the user.
For software, designed for this input type, natural mappings can be used to create a very natural interaction.
This can however quickly break down for more complex tasks, as modern tablets and smartphones have shown – they are only easily useable for consumption tasks and not for tasks that require a more complex interaction flow.
Of course using a touchscreen requires the user to stand directly by or hold the device.
Generally, interacting with it in this manner represents a gulf of execution because the user has to break his focus away from the task he wanted to fulfill.
Current technology also limits the possibilities of a device to differentiate between multiple users on a single screen, as the touch events offer no identification data.

\textbf{Near remote input} offers up more complex interaction schemes.
These range from pointing devices to ambient sensors.
With these, we can track users, either complete bodies or just hands, as required. Utilizing microphones, light barriers, or other environment sensors can also offer further or more specialized information such as the simple presence of a person.
These remote input mechanisms allow multiple users to interact with a device, via identifying them based on available criteria.
Remote input allows the user and the device with which he interacts to be placed at different locations – input can be done within a room and still be registered by the device.
This however requires a more complex coordination from a software point of view.
Another aspect that must be considered is the differentiation of privacy and how to enforce it.

\textbf{Far remote input} can also be done outside of the room the receiving device is in.
Such input is then completely location irrelevant.
However enabling or even allowing feedback becomes a non-trivial task.
Out of room remote input also decreases social contact with other humans, as controlling devices from further away takes away the need to physically be present for input.

\subsection{Input Actions}

To interact with a system a user can occupy many different input actions.
But it is not always clear which input action is most suitable.
In the following section some input actions are introduced and their advantages and disadvantages are outlined.

One possible input action is to simply \textbf{touch on a device} (or the like).
So you normally use your finger for this.
The input can be direct (direct contact with the interactive features on the user interface) or indirect (for example navigate with a touchpad).
The advantages of this approach are that a natural interaction is possible (it is normal for the user to interact in this manner), besides, the user gets feedback directly (without any lag of time). Additionally an absolute interaction (direct manipulation) is possible.
Disadvantages of this input action are that you have to be at the device to interact with it (spatial issues) and that a multi user interaction is difficult to achieve.
If there are more than one user, you need a possibility to identify the different users.
Furthermore in this case you have to deal with privacy issues (for example in a conference room) because everybody can see the user’s actions on the device.

Another possible input action is the so called \textbf{device bump}.
In this case the interaction is direct.
An advantage is that the user can realize a metaphoric transmission.
On the other hand, the interaction is unnatural for the user.
Every user also needs a (portable) device.
As aforementioned the privacy of the user has to be considered because every person in the same room notices the user’s interactions. 

Input via \textbf{pointer} is also possible and the interaction can be direct or indirect.
An absolute interaction is possible if you are interacting with a real pointer (not a mouse or the like).
Disadvantages are that the user needs a device (pointer, mouse or something else) and that you also have to face privacy issues because users can see the pointer-based interaction.

Besides the user can initiate \textbf{input with his device}.
In this case it is an indirect interaction because the user can only initiate input if he makes the detour over his device. This implicates some advantages.
Firstly, this input scenario is private and there is no problem to identify the user.
Also the functionality is immediately available with a portable device.
Some disadvantages are that no multi users are supported and every user has to have a device.
Also no absolute interaction is possible.

A further input action is \textbf{interaction via gestures} which is also an indirect input action.
In this case, natural interaction is possible and a lot of gestures can be implemented (for example for passwords).
On the other hand the number of gestures is limited to not (cognitively) overcharge the user.
Also in this case multi user actions are possible, but require a procedure to distinguish the users.
Privacy issues have to be considered because every other person in the room notices the gestures.

Another possible input action is the (indirect) interaction via \textbf{ambient sensors} (microphone, light barrier, temperature, floor, 3D sensoric and so on).
Mostly this represents a passive input modality. Also, privacy has to be considered.

\subsection{Output Actions}

Having looked at input regions and available actions, we now examine the output possibilities of such a HCI system.
Output systems are a monitor, a projection, tactile feedback, a smart device like a smartphone or smartwatch, speakers and smart artifacts and printers.

\textbf{Monitors and projections} allow simultaneos output to all people in a room, considering the monitor or projection is large enough or people are close enough.
As such they are well suited in displaying public information.
Displaying information which is only visible to single users, and thus private, is hardly possible.
One advantage to the fixed monitor is the independant projection surface of a projector.
It can be used to make any surface such as a conference table or any wall a display.
However in both cases the display usually is stationary limited to the installation of the monitor or projector.

For users interacting through touch with a monitor \textbf{tactile feedback} is possible.
The same counts for smartphones and smartwatches.
Tactile feedback is usually very discrete as the user and others are not interrupted.
As individual users can be notified it can be seen as private feedback.
Also this kind of feedback is rarely used and thus this output channel usually is available.
Disadvantages of tactile feedback is the lack of differentiation that is possible.
There is vibration with different patterns and changeable surface properties such as roughness when touching.
Tactile feedback is also of fleeting nature and its missing is possible when people are distracted or simply don’t touch the device.

\textbf{Smartphones and smartwatches} specifically can be used as output devices to give feedback everywhere.
However not every user may have such a device.
Also using them for output purposes only individual users can be targeted with feedback which is an advantage in terms of privacy.

The exception to this are speakers which give \textbf{auditive feedback}.
Auditive feedback is very dominant and thus hardly missed and reaches multiple users when loud enough.
This disturbes or interrupts the user or people in his proximity, however making it an issue for private information.
Also similar to the tactile feedback, auditive feedback is fleeting and would have to be repeated if missed.

In an office environment there are usually \textbf{printers} which can be used to output information.
They again are public as paper or 3D-models can be seen by any person present.
However this output is real and persistent for incorporation in the real world where multiple users can be reached with one device.
On the other hand, maintenance of such devices is expensive and often required.
Also printed output can be easily missed when not looking at the printer and other people seeing it may be a privacy issue.

The last output devices we examine are \textbf{smart artifacts}.
A smart artifact is a smart device in an ubiquitous-computing-supported environment such as furniture at home but also light sources, doors and home robots.
Smart artifacts can reach multiple users in their area and they allow a natural mapping of actions such as opening doors.
They are integrated in the environment and thus non-intrusive in the daily work and living.
Their public nature is an issue for private information output.
Private information can be communicated using codes.
The downside of smart artifacts is that there are not many commercial products available.